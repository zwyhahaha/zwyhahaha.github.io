**Docs:**

https://huggingface.co/spaces/Ki-Seki/ultrascale-playbook-zh-cn

https://huggingface.co/spaces/nanotron/ultrascale-playbook for distributed training

**Repos:**

https://github.com/huggingface/picotron for studying parallel mechanisms

**Some terms:**

- vllm: https://docs.vllm.ai/en/stable/ python lib for fast llm inference, better use of GPU
- k-transformers: https://kvcache-ai.github.io/ktransformers/ advanced kernel optimization and parallelism strategies 

